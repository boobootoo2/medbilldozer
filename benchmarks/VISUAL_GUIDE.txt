```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                â•‘
â•‘               GROUND TRUTH ANNOTATION SYSTEM - VISUAL GUIDE                    â•‘
â•‘                                                                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


ğŸ”´ THE PROBLEM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Benchmarks show all metrics as ZERO:

    Model Performance
    Model          Precision    Recall    F1 Score
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    MedGemma       0.00         0.00      0.00  âŒ
    OpenAI         0.00         0.00      0.00  âŒ
    Baseline       0.00         0.00      0.00  âŒ

  WHY?
  âœ— No ground truth annotations
  âœ— Nothing to compare against
  âœ— Can't measure real accuracy


ğŸŸ¢ THE SOLUTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Create ground truth JSON files defining expected issues:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ benchmarks/expected_outputs/patient_001_doc_1_medical_bill.json     â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ {                                                                   â”‚
  â”‚   "document_type": "medical_bill",                                  â”‚
  â”‚   "expected_facts": {                                               â”‚
  â”‚     "patient_name": "John Doe",                                     â”‚
  â”‚     "medical_line_items": [...]                                     â”‚
  â”‚   },                                                                â”‚
  â”‚   "expected_issues": [                                              â”‚
  â”‚     {                                                               â”‚
  â”‚       "type": "facility_fee_error",                                 â”‚
  â”‚       "description": "Excessive $500 facility fee",                 â”‚
  â”‚       "expected_savings": 300.00,                                   â”‚
  â”‚       "should_detect": true                                         â”‚
  â”‚     }                                                               â”‚
  â”‚   ],                                                                â”‚
  â”‚   "expected_savings": 300.00                                        â”‚
  â”‚ }                                                                   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  NOW Benchmarks show REAL metrics:

    Model Performance
    Model          Precision    Recall    F1 Score    Latency
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    MedGemma       0.78         0.95      0.83        2.29s    âœ…
    OpenAI         0.82         0.88      0.85        3.56s    âœ…
    Baseline       0.45         0.55      0.50        0.00s    âœ…


ğŸ“Š HOW METRICS ARE CALCULATED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  SCENARIO: Medical bill with 3 expected issues
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Expected Issues:          Detected Issues:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. Duplicate âœ“   â”‚      â”‚ 1. Duplicate âœ“   â”‚  â† Match!
    â”‚ 2. Facility Fee  â”‚      â”‚ 2. Facility Fee âœ—â”‚  â† Different message
    â”‚ 3. Unbundling   â”‚      â”‚ 3. Coding Error  â”‚  â† No match
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  MATCHING LOGIC:
    â€¢ Issues match if same TYPE (even different message)
    â€¢ Duplicate (detected) matches Duplicate (expected) = TP âœ“
    â€¢ Facility Fee (detected) matches Facility Fee (expected) = TP âœ“
    â€¢ Coding Error (detected) has no expected = FP âœ—
    â€¢ Unbundling (expected) has no detected = FN âœ—

  METRICS:
    TP = 2 (Duplicate, Facility Fee)
    FP = 1 (Coding Error wrongly detected)
    FN = 1 (Unbundling missed)

    Precision = TP / (TP + FP) = 2 / 3 = 0.67
    Recall    = TP / (TP + FN) = 2 / 3 = 0.67
    F1        = 2 * (0.67 * 0.67) / (0.67 + 0.67) = 0.67


ğŸ”„ THE WORKFLOW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  1. READ DOCUMENT
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     Review the medical bill and understand what it contains

  2. RUN ANNOTATION TOOL
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     $ python scripts/annotate_benchmarks.py \
       --input benchmarks/inputs/patient_002_doc_1_medical_bill.txt

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ ğŸ“„ Processing: patient_002...         â”‚
     â”‚                                      â”‚
     â”‚ DOCUMENT ANALYSIS                    â”‚
     â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
     â”‚                                      â”‚
     â”‚ Extracted Facts:                     â”‚
     â”‚   Patient: Jane Smith                â”‚
     â”‚   DOB: 1985-03-15                    â”‚
     â”‚   Facility: Metro Hospital           â”‚
     â”‚   Date: 2026-01-20                   â”‚
     â”‚                                      â”‚
     â”‚ Line Items (4 items):                â”‚
     â”‚   1. 99214: Office Visit - $200      â”‚
     â”‚   2. 80053: Lab Panel - $150         â”‚
     â”‚   3. 99214: Office Visit - $200 âš ï¸  â”‚ â† DUPLICATE!
     â”‚   4. 50370: Facility Fee - $800 âš ï¸  â”‚ â† EXPENSIVE!
     â”‚                                      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  3. ADD EXPECTED ISSUES
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     Options:
       1. Add issue
       2. Remove issue
       3. View issues
       4. Done

     SELECT: 1
     Issue Type: 1. duplicate_charge
     Severity: high
     Description: Duplicate office visit on line 3
     Expected Savings: 200
     Should detect? y

     âœ… Issue added

     SELECT: 1
     Issue Type: 6. excessive_charge (facility fee)
     Severity: high
     Description: Facility fee $800 is excessive for office visit
     Expected Savings: 500
     Should detect? y

     âœ… Issue added

     SELECT: 4 (Done)

  4. SAVE ANNOTATION
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     âœ… Annotation saved to:
        benchmarks/expected_outputs/patient_002_doc_1_medical_bill.json

       Issues: 2
       Expected Savings: $700.00

  5. RUN BENCHMARKS
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     $ python scripts/generate_benchmarks.py --model all

  6. CHECK RESULTS
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     View .github/README.md - now shows real metrics!


ğŸ“ FILE STRUCTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  benchmarks/
  â”‚
  â”œâ”€â”€ ğŸ“„ GROUND_TRUTH_SCHEMA.md
  â”‚   â””â”€ Defines annotation JSON format
  â”‚
  â”œâ”€â”€ ğŸ“„ ANNOTATION_GUIDE.md
  â”‚   â””â”€ Complete workflow and best practices
  â”‚
  â”œâ”€â”€ ğŸ“„ QUICK_REFERENCE.md
  â”‚   â””â”€ Quick lookup and common tasks
  â”‚
  â”œâ”€â”€ ğŸ“„ IMPLEMENTATION_NOTES.md
  â”‚   â””â”€ Technical implementation details
  â”‚
  â”œâ”€â”€ ğŸ“‚ inputs/
  â”‚   â”œâ”€â”€ patient_001_doc_1_medical_bill.txt      (Input document)
  â”‚   â”œâ”€â”€ patient_002_doc_1_medical_bill.txt
  â”‚   â”œâ”€â”€ patient_003_doc_1_medical_bill.txt
  â”‚   â””â”€â”€ ... (more documents)
  â”‚
  â”œâ”€â”€ ğŸ“‚ expected_outputs/
  â”‚   â”œâ”€â”€ patient_001_doc_1_medical_bill.json     (Ground truth)
  â”‚   â”œâ”€â”€ patient_002_doc_1_medical_bill.json
  â”‚   â”œâ”€â”€ patient_003_doc_1_medical_bill.json
  â”‚   â””â”€â”€ ... (more annotations)
  â”‚
  â””â”€â”€ ğŸ“‚ results/
      â””â”€â”€ aggregated_metrics_*.json               (Benchmark results)


ğŸ”§ KEY ISSUE TYPES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  duplicate_charge              coding_error                 unbundling
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ CPT 99213: $150    â”‚       â”‚ CPT 99215: $300    â”‚       â”‚ Ultrasound: $800   â”‚
  â”‚ CPT 99213: $150 âŒ â”‚       â”‚ (should be 99213)  â”‚       â”‚ Probe fee: $50 âŒ  â”‚
  â”‚ Total: $300        â”‚       â”‚ Total: $300        â”‚       â”‚ (should be bundled)â”‚
  â”‚ Savings: $150      â”‚       â”‚ Savings: $50       â”‚       â”‚ Savings: $50       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  facility_fee_error           excessive_charge           cross_bill_discrepancy
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Office Visit: $200 â”‚       â”‚ Lab Test: $500     â”‚       â”‚ Bill 1: Lab: $200  â”‚
  â”‚ Facility Fee: $500âŒâ”‚       â”‚ (Typical: $150)    â”‚       â”‚ Bill 2: Lab: $200âŒâ”‚
  â”‚ (normal: $50)      â”‚       â”‚ Savings: $350      â”‚       â”‚ (same charge)      â”‚
  â”‚ Savings: $450      â”‚       â”‚                    â”‚       â”‚ Savings: $200      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


âš™ï¸ SMART MATCHING ALGORITHM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  When comparing detected vs. expected issues:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ DETECTED ISSUE (from model)                                  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ {                                                            â”‚
  â”‚   "type": "facility_fee_error",                              â”‚
  â”‚   "message": "High facility fee ($500) detected",            â”‚
  â”‚   "code": null                                               â”‚
  â”‚ }                                                            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ MATCH â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ EXPECTED ISSUE (from annotation)                             â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ {                                                            â”‚
  â”‚   "type": "facility_fee_error",     â† SAME TYPE!            â”‚
  â”‚   "description": "Facility fee too high"                     â”‚
  â”‚ }                                                            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  RESULT: âœ… TRUE POSITIVE (Type matches = TP)


âœ¨ WHAT THIS ENABLES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  âœ… Real Performance Metrics
     See meaningful Precision, Recall, F1 scores instead of 0.00

  âœ… Model Comparison
     Fairly compare MedGemma, OpenAI, Gemini, Baseline on same data

  âœ… Progress Tracking
     Monitor improvements across algorithm iterations

  âœ… Realistic Evaluation
     Filter by should_detect flag - don't penalize for subtle issues

  âœ… Reproducible Benchmarks
     Annotations are versioned with code

  âœ… Easy to Extend
     Add more test cases by creating new annotation files


ğŸ“‹ STATUS & NEXT STEPS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  âœ… DONE
    â€¢ Annotation schema created
    â€¢ Benchmark script updated with smart matching
    â€¢ Interactive annotation tool provided
    â€¢ Initial annotations for 2 patients
    â€¢ Comprehensive documentation

  ğŸ”² TODO
    â€¢ Annotate remaining 8 patients (2-9)
    â€¢ Run full benchmark suite
    â€¢ Review and iterate on annotations
    â€¢ Track progress over time

  HOW TO HELP:
    1. Pick a patient (2-9)
    2. Run: python scripts/annotate_benchmarks.py --input benchmarks/inputs/...
    3. Add expected issues interactively
    4. Save and re-run benchmarks to see results


ğŸ’¡ KEY INSIGHTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Why were metrics 0.00?
    â†’ expected_issues was empty array (no annotations)
    â†’ Can't calculate precision without ground truth
    â†’ Precision = TP / (TP + FP) = 0 / (0 + 0) = undefined â†’ 0.00

  Why does "should_detect" matter?
    â†’ Some issues require medical context (too subtle for heuristics)
    â†’ should_detect=false means we won't penalize models for missing it
    â†’ But it still helps track what's realistic vs. fantasy

  Why match by type only?
    â†’ Different models describe issues differently
    â†’ MedGemma: "High facility fee"
    â†’ OpenAI: "Excessive facility charge"
    â†’ Both detect "facility_fee_error" type = both TP

  Why not match all fields?
    â†’ Message text varies too much
    â†’ Code may not be available for all issue types
    â†’ Type is the canonical match point


ğŸš€ GETTING STARTED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  1. Read the docs:
     $ cat benchmarks/GROUND_TRUTH_SCHEMA.md

  2. Annotate a document:
     $ python scripts/annotate_benchmarks.py \
       --input benchmarks/inputs/patient_002_doc_1_medical_bill.txt

  3. Run benchmarks:
     $ python scripts/generate_benchmarks.py --model all

  4. See results in .github/README.md

  That's it! ğŸ‰

```
